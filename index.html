<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <meta name="title"
    content="In-Context Brush: Zero-shot Customized Subject Insertion with Context-Aware Latent Space Manipulation - Yu Xu, Fan Tang, You Wu, Lin Gao, Oliver Deussen, Hongbin Yan, Jintao Li, Juan Cao, Tong-Yee Lee">
  <meta name="description"
    content="A zero-shot framework for customized subject insertion that seamlessly brushes user-specified objects into images using context-aware latent space manipulation without model tuning.">
  <meta name="keywords"
    content="diffusion models, subject insertion, in-context learning, image generation, zero-shot learning, machine learning, computer vision, AI">
  <meta name="author"
    content="Yu Xu, Fan Tang, You Wu, Lin Gao, Oliver Deussen, Hongbin Yan, Jintao Li, Juan Cao, Tong-Yee Lee">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">


  <!-- Academic/Research Specific -->
  <meta name="citation_title"
    content="In-Context Brush: Zero-shot Customized Subject Insertion with Context-Aware Latent Space Manipulation">
  <meta name="citation_author" content="Xu, Yu">
  <meta name="citation_author" content="Tang, Fan">
  <meta name="citation_author" content="Wu, You">
  <meta name="citation_author" content="Gao, Lin">
  <meta name="citation_author" content="Deussen, Oliver">
  <meta name="citation_author" content="Yan, Hongbin">
  <meta name="citation_author" content="Li, Jintao">
  <meta name="citation_author" content="Cao, Juan">
  <meta name="citation_author" content="Lee, Tong-Yee">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_journal" content="arXiv preprint arXiv:2505.20271">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2505.20271.pdf">

  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>In-Context Brush: Zero-shot Customized Subject Insertion</title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>

  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "In-Context Brush: Zero-shot Customized Subject Insertion with Context-Aware Latent Space Manipulation",
    "description": "A zero-shot framework for customized subject insertion that seamlessly brushes user-specified objects into images using context-aware latent space manipulation without model tuning.",
    "author": [
      {
        "@type": "Person",
        "name": "Yu Xu",
        "affiliation": {
          "@type": "Organization",
          "name": "Institute of Computing Technology, Chinese Academy of Sciences"
        }
      },
      {
        "@type": "Person",
        "name": "Fan Tang",
        "affiliation": {
          "@type": "Organization",
          "name": "Institute of Computing Technology, Chinese Academy of Sciences"
        }
      }
    ],
    "datePublished": "2024-05-30",
    "publisher": {
      "@type": "Organization",
      "name": "arXiv"
    },
    "keywords": ["diffusion models", "subject insertion", "in-context learning", "image generation", "zero-shot learning", "machine learning", "computer vision"],
    "abstract": "Recent advances in diffusion models have enhanced multimodal-guided visual generation, enabling customized subject insertion that seamlessly brushes user-specified objects into a given image guided by textual prompts. However, existing methods often struggle to insert customized subjects with high fidelity and align results with the user's intent through textual prompts. In this work, we propose In-Context Brush, a zero-shot framework for customized subject insertion by reformulating the task within the paradigm of in-context learning. Without loss of generality, we formulate the object image and the textual prompts as cross-modal demonstrations, and the target image with the masked region as the query. The goal is to inpaint the target image with the subject aligning textual prompts without model tuning. Building upon a pretrained MMDiT-based inpainting network, we perform test-time enhancement via dual-level latent space manipulation: intra-head latent feature shifting within each attention head that dynamically shifts attention outputs to reflect the desired subject semantics and inter-head attention reweighting across different heads that amplifies prompt controllability through differential attention prioritization. Extensive experiments and applications demonstrate that our approach achieves superior identity preservation, text alignment, and image quality compared to existing state-of-the-art methods, without requiring dedicated training or additional data collection.",
    "citation": "@article{xu2024incontext, title={In-Context Brush: Zero-shot Customized Subject Insertion with Context-Aware Latent Space Manipulation}, author={Yu Xu and Fan Tang and You Wu and Lin Gao and Oliver Deussen and Hongbin Yan and Jintao Li and Juan Cao and Tong-Yee Lee}, journal={arXiv preprint arXiv:2505.20271}, year={2024}, url={https://arxiv.org/abs/2505.20271}}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "about": [
      {
        "@type": "Thing",
        "name": "Diffusion Models"
      },
      {
        "@type": "Thing", 
        "name": "In-Context Learning"
      }
    ]
  }
  </script>
</head>

<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-up dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="works-list">
        <a href="https://yuci-gpt.github.io/headrouter/" class="work-item" target="_blank">
          <div class="work-info">
            <h5>HeadRouter: A Training-free Image Editing Framework for MM-DiTs by Adaptively Routing Attention Heads</h5>
            <span class="work-venue">2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://yuci-gpt.github.io/B4M/" class="work-item" target="_blank">
          <div class="work-info">
            <h5>B4M: Breaking Low-Rank Adapter for Making Content-Style Customization</h5>
            <span class="work-venue">2025</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://yuci-gpt.github.io/TAG-MoE/" class="work-item" target="_blank">
          <div class="work-info">
            <h5>TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts</h5>
            <span class="work-venue">2025</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">In-Context Brush: Zero-shot Customized Subject Insertion with
                Context-Aware Latent Space Manipulation</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=TXI4OQMAAAAJ" target="_blank">Yu Xu</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=PdKElfwAAAAJ" target="_blank">Fan Tang</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=OKHbHBEAAAAJ" target="_blank">You Wu</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=_RIupXUAAAAJ" target="_blank">Lin Gao</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=y3j0c80AAAAJ" target="_blank">Oliver Deussen</a><sup>3</sup>,</span>
                <span class="author-block">
                  <a href="https://academic.hongb.in/" target="_blank">Hongbin Yan</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="https://ieeexplore.ieee.org/author/37279850400" target="_blank">Jintao Li</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=fSBdNg0AAAAJ" target="_blank">Juan Cao</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="http://graphics.csie.ncku.edu.tw/Tony/tony.htm" target="_blank">Tong-Yee Lee</a><sup>4</sup>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>Institute of Computing Technology, Chinese Academy of
                  Sciences<br><sup>2</sup>University of Chinese Academy of Sciences<br><sup>3</sup>University of
                  Konstanz<br><sup>4</sup>National Cheng-Kung University</span>
              </div>

              <div class="publication-venue">
                <span class="venue-block">ACM SIGGRAPH ASIA 2025</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2505.20271.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2505.20271" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>


                  <span class="link-block">
                    <a href="https://github.com/ICTMCG/In-context-Brush" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code (coming soon)</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- Teaser video-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/videos/banner_video.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Our method achieves identity-preserving subject insertion in novel scenes harmoniously, simultaneously enabling diverse text-driven control.
          </h2>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-10-desktop is-11-tablet is-12-mobile">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified glass-card">
              <p>
                Recent advances in diffusion models have enhanced multimodal-guided visual generation, enabling customized subject insertion that seamlessly "brushes" user-specified objects into a given image guided by textual prompts. However, existing methods often struggle to insert customized subjects with high fidelity and align results with the user's intent through textual prompts. In this work, we propose "In-Context Brush", a zero-shot framework for customized subject insertion by reformulating the task within the paradigm of in-context learning. Without loss of generality, we formulate the object image and the textual prompts as cross-modal demonstrations, and the target image with the masked region as the query. The goal is to inpaint the target image with the subject aligning textual prompts without model tuning. Building upon a pretrained MMDiT-based inpainting network, we perform test-time enhancement via dual-level latent space manipulation: intra-head "latent feature shifting" within each attention head that dynamically shifts attention outputs to reflect the desired subject semantics and inter-head "attention reweighting" across different heads that amplifies prompt controllability through differential attention prioritization. Extensive experiments and applications demonstrate that our approach achieves superior identity preservation, text alignment, and image quality compared to existing state-of-the-art methods, without requiring dedicated training or additional data collection.
              </p>

              <!-- Representative figure -->
              <div class="has-text-centered" style="margin-top: 2rem;">
                <img src="./static/images/representative_image.jpg" alt="" style="max-width: 100%; height: auto;"/>
                <p class="subtitle has-text-centered" style="margin-top: 1rem; font-size: 1rem; color: var(--text-primary);">
                  Our method achieves identity-preserving subject insertion in novel scenes harmoniously, simultaneously enabling diverse text-driven control.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->


    <!-- Method section -->
    <section class="section hero">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-10-desktop is-11-tablet is-12-mobile">
            <h2 class="title is-3">Method</h2>
            <div class="content has-text-justified glass-card">
              <div class="has-text-centered" style="margin-bottom: 2rem;">
                <img src="./static/images/method.png" alt="" style="max-width: 100%; height: auto;"/>
              </div>
              <p>
                We mainly introduce latent space shifting for subject present in target images in a training-free manner. In the “Latent Feature Shifting” part, features from the reference are shifted to output. We propose attention heads activation for further enhance representation of textual prompts and token blending for consistency injection within the image.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End method section -->


    <!-- Experiments section -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-10-desktop is-11-tablet is-12-mobile">
            <h2 class="title is-3">Experiments</h2>
            <div class="content has-text-justified glass-card">
              <div class="has-text-centered" style="margin-bottom: 2rem;">
                <img src="./static/images/experiments.png" alt="" style="max-width: 100%; height: auto;"/>
                <p class="subtitle has-text-centered" style="margin-top: 1rem; font-size: 1rem; color: var(--text-primary);">
                  Qualitative comparison on subject injection and editing with baseline methods.
                </p>
              </div>
              <p>
                Results of our results maintain identity consistency with reference while preserving fine-grained features, and are also aligning with the prompts. Masks are labeled as white boxes on target images.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End experiments section -->


    <!-- Applications section -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered" style="margin-bottom: 2rem;">Applications</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <img src="static/images/applications_virtual_try_on.png"
                alt="" loading="lazy" />
              <h2 class="subtitle has-text-centered">
                <strong>Virtual Try-On.</strong>
              </h2>
            </div>
            <div class="item">
              <img src="static/images/applications_compositional_generation.png"
                alt="" loading="lazy" />
              <h2 class="subtitle has-text-centered">
                <strong>Compositional Generation.</strong>
              </h2>
            </div>
            <div class="item">
              <img src="static/images/applications_partly_insertion.png" alt=""
                loading="lazy" />
              <h2 class="subtitle has-text-centered">
                <strong>Partial Insertion.</strong>
              </h2>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End applications section -->


    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>@article{xu2025incontextbrushzeroshotcustomized,
      title={In-Context Brush: Zero-shot Customized Subject Insertion with Context-Aware Latent Space Manipulation}, 
      author={Yu Xu and Fan Tang and You Wu and Lin Gao and Oliver Deussen and Hongbin Yan and Jintao Li and Juan Cao and Tong-Yee Lee},
      year={2025},
      eprint={2505.20271},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.20271}, 
}</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a> which was adopted from the <a
                  href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                You are free to borrow the source code of this website, we just ask that you link back to this page in
                the footer. <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>